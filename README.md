# Entity Matching with 7B LLMs (Reprodu√ß√£o)

Este reposit√≥rio cont√©m a reprodu√ß√£o parcial do artigo **‚ÄúEntity Matching with 7B LLMs: A Study on Prompting Strategies and Hardware Limitations‚Äù**, com foco na aplica√ß√£o de **modelos LLM de 7 bilh√µes de par√¢metros** (notadamente **Orca2**) para a tarefa de *entity matching* utilizando **prompting zero-shot e few-shot**.

> üî¨ Esta reprodu√ß√£o foi realizada com recursos computacionais limitados e teve como principal objetivo verificar a reprodutibilidade dos resultados do artigo original utilizando o dataset **Abt-Buy**.

## üìÅ Estrutura do Reposit√≥rio

```
.
‚îú‚îÄ‚îÄ data/                  # Datasets e arquivos de prompt
‚îÇ   ‚îú‚îÄ‚îÄ Abt.csv
‚îÇ   ‚îú‚îÄ‚îÄ Buy.csv
‚îÇ   ‚îú‚îÄ‚îÄ abt_buy_perfectMapping.csv
‚îÇ   ‚îî‚îÄ‚îÄ ...                # Arquivos de prompt gerados
‚îú‚îÄ‚îÄ results/               # Resultados das execu√ß√µes com LLMs
‚îú‚îÄ‚îÄ scripts/               # Scripts Python organizados por etapa
‚îÇ   ‚îú‚îÄ‚îÄ 1_generate_pairs.py
‚îÇ   ‚îú‚îÄ‚îÄ 2_generate_prompts.py
‚îÇ   ‚îú‚îÄ‚îÄ 3_apply_llm.py
‚îÇ   ‚îú‚îÄ‚îÄ 4_evaluate_results.py
‚îÇ   ‚îî‚îÄ‚îÄ utils.py           # Fun√ß√µes auxiliares
‚îî‚îÄ‚îÄ README.md
```

## üì¶ Datasets

Os datasets utilizados foram:

- **Abt-Buy**:
[Link](https://paperswithcode.com/dataset/abt-buy)
[Download direto](https://dbs.uni-leipzig.de/files/datasets/Abt-Buy.zip)
- **Walmart-Amazon**:
[Link](https://www.kaggle.com/datasets/satriowp/amazonwalmart-dataset?resource=download&SSORegistrationToken=CfDJ8KT8tnOr7fFFm_byYmusL7h5Ty19or31iMUbEDc69D6JJj5V58Gr-d6lJ4HJkStuuZ8KpAqQ9GdoXf0FoxrVLXdroisIQzkqb7h8f-tke0w3X0fw8Kkim5FOpjR7wHrjPKlKPquGUQ27cGN1vR9NtC1uLmwvQ_ajiD6_eIlJkilQicMeK4bpcQxH9bdUEF1QrUDh1WdFniYvAAhL-BW53GkMXbeG7Uprj8uTxWybyalKY1oAL7q62gX1BosGDkmLqf_4Jm2hmtNM-KMwvja6wc8kBJ0eierSchIiiny0HYQWDp7NZvOdK7OtEgUefAXgAUlnkRm6cMoDT0_fWPA4HXM&DisplayName=Hony%20A%20Nascimento)

---

## üöÄ Como Executar

### 1. Instale as depend√™ncias

```bash
pip install -r requirements.txt
```

> M√≥dulos principais: `pandas`, `tqdm`, `scikit-learn`, `ollama`

### 2. Prepare os pares de dados

```bash
python scripts/1_generate_pairs.py
```

### 3. Gere os prompts

```bash
python scripts/2_generate_prompts.py
```

### 4. Execute os modelos LLM

```bash
python scripts/3_apply_llm.py
```

> ‚ö†Ô∏è Tempo estimado para Orca2 zero-shot: ~21h com CPU; few-shot: ~32h

### 5. Avalie os resultados

```bash
python scripts/4_evaluate_results.py
```

## üìä Resultados Obtidos

| Estrat√©gia       | Fonte        | Precision | Recall | F1-score | Tempo Execu√ß√£o |
|------------------|--------------|-----------|--------|----------|----------------|
| Zero-shot        | Artigo       | 0.664     | 0.956  | 0.784    | -              |
| Zero-shot        | Reprodu√ß√£o   | 0.9971    | 0.6462 | 0.7842   | 20h 58min      |
| Few-shot (FT)    | Artigo       | 0.768     | 0.834  | 0.799    | -              |
| Few-shot (FT)    | Reprodu√ß√£o   | 1.0000    | 0.4000 | 0.5714   | 32h 27min      |

## ‚öôÔ∏è Requisitos

- Python 3.13.3
- Ollama 0.9.2 com o modelo [Orca2](https://ollama.com/library/orca2) instalado
- Mem√≥ria RAM recomendada: 16GB+
- Ambiente testado com CPU (i7-8750H) e GPU GTX 1050 (4GB)

Na primeira vers√£o do experimento foi utilizado o seguinte hardware:
- Notebook Dell G7 15 7588 (SO Windows)
- Processador i7-8750H (2.20GHz)
- 16 GB de mem√≥ria RAM 
- GPU NVIDIA GTX 1050 4GB


## üìå Observa√ß√µes

- Devido a limita√ß√µes de hardware, o dataset **Walmart-Amazon** n√£o foi processado.
- Os exemplos few-shot utilizados foram **gen√©ricos**, o que pode ter afetado o desempenho.
- O c√≥digo est√° modularizado para permitir reuso e expans√£o em experimentos futuros.

## üìé Refer√™ncia Original

Arvanitis-Kasinikos, I., & Papadakis, G. (2025). *Entity Matching with 7B LLMs: A Study on Prompting Strategies and Hardware Limitations*. DOLAP 2025.
